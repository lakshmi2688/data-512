{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Bias in data : Analysis 2</h1> \n",
    "\n",
    "<h3>Analyze the comments dataset for all the comments datasets and  answer some of the following questions</h3>\n",
    "<ul><li>Analyze the words most commonly associated with each of the three types of hostile speech</li>\n",
    "    <li>Are certain words more likely to be associated with comments labelled as hostile speech? Are there certain words that are frequently associated with one type of hostile speech (like “personal attacks”) but not others (like “toxicity”)?</li>\n",
    "    <li>Are these words representative of words that you would associate with hostile speech? Do you think these frequently labelled words are a good representation of hostile speech in online discussions outside of Wikipedia? Of offline discussions? Why or why not?</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2>\n",
    "Step 1: Background\n",
    "</h2>\n",
    "\n",
    "<p>The goal of this assignment is to identify what, if any, sources of bias may exist in these datasets, and to develop testable hypotheses about how these biases might impact the behavior of machine learning models trained on the data, when those models are used for research purposes or to power data-driven applications. The purpose of this assignment is to demonstrate that you are able to perform a self-directed exploratory data analysis and think critically about the implications of your findings.</p>\n",
    "\n",
    "<p>The corpus we use for the detox project is called the Wikipedia Talk corpus, and it consists of three datasets. Each dataset contains thousands of online discussion posts made by Wikipedia editors who were discussing how to write and edit Wikipedia articles. Crowdworkers labelled these posts for three kinds of hostile speech: “toxicity”, “aggression”, and “personal attacks”. Many posts in each dataset were labelled by multiple crowdworkers for each type of hostile speech, to improve accuracy.</p>\n",
    "\n",
    "<p>Google data scientists used these <a href='https://figshare.com/projects/Wikipedia_Talk/16731'>annotated datasets</a> to train machine learning models as part of a project called <a href='https://conversationai.github.io/'>Conversation AI</a>. The models have been used in a variety of software products and made freely accessible to anyone through the Perspective API. </p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>All data we have collected and generated for the <a href='https://meta.wikimedia.org/wiki/Research:Detox'>Wikipedia Detox</a> project is available under free licenses on the <a href ='https://figshare.com/projects/Wikipedia_Talk/16731'>Wikipedia Talk Corpus on Figshare</a>, per the <a href='https://foundation.wikimedia.org/wiki/Open_access_policy'>open access policy</a>. There are currently two distinct types of data included:<p>\n",
    "   <ol><li> A corpus of all 95 million user and article talk diffs made between 2001–2015 which can be scored by our personal attacks model.</li>\n",
    "   <li> An annotated dataset of 1m crowd-sourced annotations that cover 100k talk page diffs (with 10 judgements per diff) for personal attacks, aggression, and toxicity.</li></ol>\n",
    "<h4>These datasets can be downloaded from the below links</h4>\n",
    "\n",
    "<ul><li>https://figshare.com/articles/dataset/Wikipedia_Talk_Labels_Aggression/4267550</li>\n",
    "<li>https://figshare.com/articles/dataset/Wikipedia_Talk_Labels_Toxicity/4563973</li>\n",
    "<li>https://figshare.com/articles/dataset/Wikipedia_Talk_Labels_Personal_Attacks/4054689</li>\n",
    "<li>https://figshare.com/articles/dataset/Wikipedia_Talk_Corpus/4264973</li></ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Step 2: Analysis of Personal Attacks, Toxicity and Aggression datasets </h2>\n",
    "    \n",
    "    \n",
    "<h4><em>We start with importing all the packages we need for doing the data analysis. </em></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import collections\n",
    "from collections import Counter "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><em>Download annotated comments,annotations and demographic datasets for personal attack directly from the urls and save them as .tsv files</em></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download annotated comments,annotations and demographics for personal attack\n",
    "\n",
    "personal_attacks_annotations_url = 'https://ndownloader.figshare.com/files/7554637' \n",
    "personal_attacks_annotated_comments_url = 'https://ndownloader.figshare.com/files/7554634' \n",
    "personal_attacks_worker_demographics_url = 'https://ndownloader.figshare.com/files/7640752'\n",
    "\n",
    "\n",
    "def download_file(url, fname):\n",
    "    urllib.request.urlretrieve(url, fname)\n",
    "\n",
    "                \n",
    "download_file(personal_attacks_annotations_url , 'personal_attacks_annotations.tsv')\n",
    "download_file(personal_attacks_annotated_comments_url, 'personal_attacks_annotated_comments.tsv')\n",
    "download_file(personal_attacks_worker_demographics_url, 'personal_attacks_worker_demographics.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><em>Download annotated comments,annotations and demographic datasets for toxicity directly from the urls and save them as .tsv files</em></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download annotated comments,annotations and demographic details for toxicity\n",
    "\n",
    "toxicity_annotations_url = 'https://ndownloader.figshare.com/files/7394539' \n",
    "toxicity_annotated_comments_url = 'https://ndownloader.figshare.com/files/7394542' \n",
    "toxicity_worker_demographics_url = 'https://ndownloader.figshare.com/files/7640581'\n",
    "\n",
    "def download_file(url, fname):\n",
    "    urllib.request.urlretrieve(url, fname)\n",
    "                \n",
    "download_file(toxicity_annotations_url , 'toxicity_annotations.tsv')\n",
    "download_file(toxicity_annotated_comments_url, 'toxicity_annotated_comments.tsv')\n",
    "download_file(toxicity_worker_demographics_url, 'toxicity_worker_demographics.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><em>Download annotated comments,annotations and demographic datasets for aggression directly from the urls and save them as .tsv files</em></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download annotated comments,annotations and demographic details for aggression\n",
    "\n",
    "aggression_annotations_url = 'https://ndownloader.figshare.com/files/7394506' \n",
    "aggression_annotated_comments_url = 'https://ndownloader.figshare.com/files/7038038' \n",
    "aggression_worker_demographics_url = 'https://ndownloader.figshare.com/files/7640644'\n",
    "\n",
    "def download_file(url, fname):\n",
    "    urllib.request.urlretrieve(url, fname)\n",
    "                \n",
    "download_file(aggression_annotations_url , 'aggression_annotations.tsv')\n",
    "download_file(aggression_annotated_comments_url, 'aggression_annotated_comments.tsv')\n",
    "download_file(aggression_worker_demographics_url, 'aggression_worker_demographics.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><em> Read all the .tsv files as tab seperated files for personal attacks and save them as python dataframes </em></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_attacks_comments = pd.read_csv('personal_attacks_annotated_comments.tsv', sep = '\\t', index_col = 0)\n",
    "personal_attacks_demographics = pd.read_csv('personal_attacks_worker_demographics.tsv',  sep = '\\t')\n",
    "personal_attacks_annotations = pd.read_csv('personal_attacks_annotations.tsv',  sep = '\\t');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxicity_comments = pd.read_csv('toxicity_annotated_comments.tsv', sep = '\\t', index_col = 0)\n",
    "toxicity_demographics = pd.read_csv('toxicity_worker_demographics.tsv',  sep = '\\t')\n",
    "toxicity_annotations = pd.read_csv('toxicity_annotations.tsv',  sep = '\\t');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggression_comments = pd.read_csv('aggression_annotated_comments.tsv', sep = '\\t', index_col = 0)\n",
    "aggression_demographics = pd.read_csv('aggression_worker_demographics.tsv',  sep = '\\t')\n",
    "aggression_annotations = pd.read_csv('aggression_annotations.tsv',  sep = '\\t');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> Lets understand the different columns in the comments dataset</strong>\n",
    "\n",
    "<ul><li><strong>rev_id: </strong> MediaWiki revision id of the edit that added the comment to a talk page (i.e. discussion).</li>\n",
    "<li><strong>comment: </strong> Comment text. Consists of the concatenation of content added during a revision/edit of a talk page. MediaWiki markup and HTML have been stripped out. To simplify tsv parsing, \\n has been mapped to NEWLINE_TOKEN, \\t has been mapped to TAB_TOKEN and \" has been mapped to \".</li>\n",
    "<li><strong>year: </strong> The year the comment was posted in.</li>\n",
    "<li><strong>logged_in: </strong> Indicator for whether the user who made the comment was logged in. Takes on values in {0, 1}.</li>\n",
    "<li><strong>ns: </strong>Namespace of the discussion page the comment was made in. Takes on values in {user, article}.</li>\n",
    "<li><strong>sample: </strong> Indicates whether the comment came via random sampling of all comments, or whether it came from random sampling of the 5 comments around a block event for violating WP:npa or WP:HA. Takes on values in {random, blocked}.</li>\n",
    "<li><strong>split: </strong> For model building in our paper we split comments into train, dev and test sets. Takes on values in {train, dev, test}.</li></ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Potential sources of bias:</h3>\n",
    "\n",
    "<ul><li><strong>Features missing values: </strong> Dataframe.count() gives the count of records that have values populated for each column in the dataset. If the dataset has missing values for features for a large number of examples, then that could be an indicator that certain characteristics of the data set are under-represented. Here we observe that no values are missing for any of the features in comments dataset</li>\n",
    "    \n",
    "<p><li><strong>Omitted variable bias: </strong> The research paper highlights that machines are being trained purely on features extracted only from the comment text instead of including features based on the authors’ past behavior and the discussion context. This means that we may be omitting some features which could be directly correlated with the response variable. For example, people’s cultural backgrounds and personal sensibilities play a significant role in whether they perceive content as personal attack. So considering information beyond the text, such as demographic\n",
    "information about the speaker, can improve the accuracy for personal attack detection. Having some background information about the user of a post may be very predictive. A user who is known to write hate speech messages may do so again. A user who is not known to write such messages is unlikely to do so in the future. We do not have this information available. Also, without taking the context into account, the models will be not trained to generalize to unseen examples.</li></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>We do the following in the below chunk of code: </strong>\n",
    "<ul> \n",
    "    <li>Get an idea of what the comments dataset looks like using the dataframe.head()</li>\n",
    "    <li>Get the count of missing values in the dataset using dataframe.count(). We infer from the results that none of the values are missing for any of the features</li>\n",
    "    <li>Repeat bullet points 1 and 2 for all comments datasets</li>\n",
    "<ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rev_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37675</th>\n",
       "      <td>`-NEWLINE_TOKENThis is not ``creative``.  Thos...</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44816</th>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKEN:: the term ``stand...</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49851</th>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKENTrue or false, the s...</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89320</th>\n",
       "      <td>Next, maybe you could work on being less cond...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93890</th>\n",
       "      <td>This page will need disambiguation.</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  comment  year  logged_in  \\\n",
       "rev_id                                                                       \n",
       "37675   `-NEWLINE_TOKENThis is not ``creative``.  Thos...  2002      False   \n",
       "44816   `NEWLINE_TOKENNEWLINE_TOKEN:: the term ``stand...  2002      False   \n",
       "49851   NEWLINE_TOKENNEWLINE_TOKENTrue or false, the s...  2002      False   \n",
       "89320    Next, maybe you could work on being less cond...  2002       True   \n",
       "93890                This page will need disambiguation.   2002       True   \n",
       "\n",
       "             ns  sample  split  \n",
       "rev_id                          \n",
       "37675   article  random  train  \n",
       "44816   article  random  train  \n",
       "49851   article  random  train  \n",
       "89320   article  random    dev  \n",
       "93890   article  random  train  "
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "personal_attacks_comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rev_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2232.0</th>\n",
       "      <td>This:NEWLINE_TOKEN:One can make an analogy in ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4216.0</th>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKEN:Clarification for ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8953.0</th>\n",
       "      <td>Elected or Electoral? JHK</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26547.0</th>\n",
       "      <td>`This is such a fun entry.   DevotchkaNEWLINE_...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28959.0</th>\n",
       "      <td>Please relate the ozone hole to increases in c...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   comment  year  logged_in  \\\n",
       "rev_id                                                                        \n",
       "2232.0   This:NEWLINE_TOKEN:One can make an analogy in ...  2002       True   \n",
       "4216.0   `NEWLINE_TOKENNEWLINE_TOKEN:Clarification for ...  2002       True   \n",
       "8953.0                           Elected or Electoral? JHK  2002      False   \n",
       "26547.0  `This is such a fun entry.   DevotchkaNEWLINE_...  2002       True   \n",
       "28959.0  Please relate the ozone hole to increases in c...  2002       True   \n",
       "\n",
       "              ns  sample  split  \n",
       "rev_id                           \n",
       "2232.0   article  random  train  \n",
       "4216.0      user  random  train  \n",
       "8953.0   article  random   test  \n",
       "26547.0  article  random  train  \n",
       "28959.0  article  random   test  "
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxicity_comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rev_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37675</th>\n",
       "      <td>`-NEWLINE_TOKENThis is not ``creative``.  Thos...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44816</th>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKEN:: the term ``stand...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49851</th>\n",
       "      <td>NEWLINE_TOKENNEWLINE_TOKENTrue or false, the s...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89320</th>\n",
       "      <td>Next, maybe you could work on being less cond...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93890</th>\n",
       "      <td>This page will need disambiguation.</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  comment  year  logged_in  \\\n",
       "rev_id                                                                       \n",
       "37675   `-NEWLINE_TOKENThis is not ``creative``.  Thos...  2002       True   \n",
       "44816   `NEWLINE_TOKENNEWLINE_TOKEN:: the term ``stand...  2002       True   \n",
       "49851   NEWLINE_TOKENNEWLINE_TOKENTrue or false, the s...  2002       True   \n",
       "89320    Next, maybe you could work on being less cond...  2002       True   \n",
       "93890                This page will need disambiguation.   2002       True   \n",
       "\n",
       "             ns  sample  split  \n",
       "rev_id                          \n",
       "37675   article  random  train  \n",
       "44816   article  random  train  \n",
       "49851   article  random  train  \n",
       "89320   article  random    dev  \n",
       "93890   article  random  train  "
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggression_comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment      115864\n",
       "year         115864\n",
       "logged_in    115864\n",
       "ns           115864\n",
       "sample       115864\n",
       "split        115864\n",
       "dtype: int64"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "personal_attacks_comments.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment      159686\n",
       "year         159686\n",
       "logged_in    159686\n",
       "ns           159686\n",
       "sample       159686\n",
       "split        159686\n",
       "dtype: int64"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxicity_comments.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment      115864\n",
       "year         115864\n",
       "logged_in    115864\n",
       "ns           115864\n",
       "sample       115864\n",
       "split        115864\n",
       "dtype: int64"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggression_comments.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>The below code chunk does the following</strong>\n",
    "<ul><li>Remove newline and tab tokens from <strong>personal_attacks_comments</strong> dataset</li>\n",
    "    <li>Label a comment as an attack if the majority of annotators did so. Here we assume a classifier threshold of 0.5, that is when more than 50% of annotators quote a comment as attack, we consider it an attack</li>\n",
    "    <li>Join the comments with labels</li>\n",
    "    <li>Display comments from the dataframe where attack is True using dataframe.query</li>\n",
    "    <li>Display the dataframe using dataframe.head() function</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_attacks_comments['comment'] = personal_attacks_comments['comment'].apply(lambda x: x.replace(\"NEWLINE_TOKEN\", \" \"))\n",
    "personal_attacks_comments['comment'] = personal_attacks_comments['comment'].apply(lambda x: x.replace(\"TAB_TOKEN\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>attack</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rev_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37675</th>\n",
       "      <td>`- This is not ``creative``.  Those are the di...</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44816</th>\n",
       "      <td>`  :: the term ``standard model`` is itself le...</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49851</th>\n",
       "      <td>True or false, the situation as of March 200...</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89320</th>\n",
       "      <td>Next, maybe you could work on being less cond...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>dev</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93890</th>\n",
       "      <td>This page will need disambiguation.</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  comment  year  logged_in  \\\n",
       "rev_id                                                                       \n",
       "37675   `- This is not ``creative``.  Those are the di...  2002      False   \n",
       "44816   `  :: the term ``standard model`` is itself le...  2002      False   \n",
       "49851     True or false, the situation as of March 200...  2002      False   \n",
       "89320    Next, maybe you could work on being less cond...  2002       True   \n",
       "93890                This page will need disambiguation.   2002       True   \n",
       "\n",
       "             ns  sample  split  attack  \n",
       "rev_id                                  \n",
       "37675   article  random  train   False  \n",
       "44816   article  random  train   False  \n",
       "49851   article  random  train   False  \n",
       "89320   article  random    dev   False  \n",
       "93890   article  random  train   False  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = personal_attacks_annotations.groupby('rev_id')['attack'].mean() > 0.5\n",
    "personal_attacks_comments['attack'] = labels\n",
    "personal_attacks_comments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>The below code chunk does the following</strong>\n",
    "<ul><li>Remove newline and tab tokens from <strong>toxicity_comments</strong> dataset</li>\n",
    "    <li>Label a comment as toxic if the majority of annotators did so. Here we assume a classifier threshold of 0.5, that is when more than 50% of annotators quote a comment as attack, we consider it an attack</li>\n",
    "    <li>Join the comments with labels</li>\n",
    "    <li>Display comments from the dataframe where attack is True using dataframe.query</li>\n",
    "    <li>Display the dataframe using dataframe.head() function</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxicity_comments['comment'] = toxicity_comments['comment'].apply(lambda x: x.replace(\"NEWLINE_TOKEN\", \" \"))\n",
    "toxicity_comments['comment'] = toxicity_comments['comment'].apply(lambda x: x.replace(\"TAB_TOKEN\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>toxicity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rev_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2232.0</th>\n",
       "      <td>This: :One can make an analogy in mathematical...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4216.0</th>\n",
       "      <td>`  :Clarification for you  (and Zundark's righ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8953.0</th>\n",
       "      <td>Elected or Electoral? JHK</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26547.0</th>\n",
       "      <td>`This is such a fun entry.   Devotchka  I once...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28959.0</th>\n",
       "      <td>Please relate the ozone hole to increases in c...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   comment  year  logged_in  \\\n",
       "rev_id                                                                        \n",
       "2232.0   This: :One can make an analogy in mathematical...  2002       True   \n",
       "4216.0   `  :Clarification for you  (and Zundark's righ...  2002       True   \n",
       "8953.0                           Elected or Electoral? JHK  2002      False   \n",
       "26547.0  `This is such a fun entry.   Devotchka  I once...  2002       True   \n",
       "28959.0  Please relate the ozone hole to increases in c...  2002       True   \n",
       "\n",
       "              ns  sample  split  toxicity  \n",
       "rev_id                                     \n",
       "2232.0   article  random  train     False  \n",
       "4216.0      user  random  train     False  \n",
       "8953.0   article  random   test     False  \n",
       "26547.0  article  random  train     False  \n",
       "28959.0  article  random   test     False  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = toxicity_annotations.groupby('rev_id')['toxicity'].mean() > 0.5\n",
    "toxicity_comments['toxicity'] = labels\n",
    "toxicity_comments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>The below code chunk does the following</strong>\n",
    "<ul><li>Remove newline and tab tokens from <strong>aggression_comments</strong> dataset</li>\n",
    "    <li>Label a comment as aggressive if the majority of annotators did so. Here we assume a classifier threshold of 0.5, that is when more than 50% of annotators quote a comment as attack, we consider it an attack</li>\n",
    "    <li>Join the comments with labels</li>\n",
    "    <li>Display comments from the dataframe where attack is True using dataframe.query</li>\n",
    "    <li>Display the dataframe using dataframe.head() function</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggression_comments['comment'] = aggression_comments['comment'].apply(lambda x: x.replace(\"NEWLINE_TOKEN\", \" \"))\n",
    "aggression_comments['comment'] = aggression_comments['comment'].apply(lambda x: x.replace(\"TAB_TOKEN\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>aggression</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rev_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37675</th>\n",
       "      <td>`- This is not ``creative``.  Those are the di...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44816</th>\n",
       "      <td>`  :: the term ``standard model`` is itself le...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49851</th>\n",
       "      <td>True or false, the situation as of March 200...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89320</th>\n",
       "      <td>Next, maybe you could work on being less cond...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>dev</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93890</th>\n",
       "      <td>This page will need disambiguation.</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  comment  year  logged_in  \\\n",
       "rev_id                                                                       \n",
       "37675   `- This is not ``creative``.  Those are the di...  2002       True   \n",
       "44816   `  :: the term ``standard model`` is itself le...  2002       True   \n",
       "49851     True or false, the situation as of March 200...  2002       True   \n",
       "89320    Next, maybe you could work on being less cond...  2002       True   \n",
       "93890                This page will need disambiguation.   2002       True   \n",
       "\n",
       "             ns  sample  split  aggression  \n",
       "rev_id                                      \n",
       "37675   article  random  train       False  \n",
       "44816   article  random  train       False  \n",
       "49851   article  random  train       False  \n",
       "89320   article  random    dev       False  \n",
       "93890   article  random  train       False  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = aggression_annotations.groupby('rev_id')['aggression'].mean() > 0.5\n",
    "aggression_comments['aggression'] = labels\n",
    "aggression_comments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We call the function <strong>kFreqWord</strong> by passing in the cleaned up comments that are perceived personal attacks and also an interger k which represents count of words most frequently occurring in the comments</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kFreqWord(str_list,k):\n",
    "    l = str_list.tolist()\n",
    "    split_it =[i.split()[0] for i in l]\n",
    "    count = Counter(split_it)\n",
    "    most_occur = count.most_common(k) \n",
    "    return most_occur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The function <strong>identityInComment</strong> takes in 2 arguments, list of identity words and list of comments that are perceived as personal attacks. Identity words represent the frequently targeted groups. The function returns number of times identity words are repeated in a comment. For example, if a comment has words \"black\" and \"woman\", then count of the identify words = 2 in a single comment</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identityInComment(str_list,identity_list):\n",
    "    \n",
    "    count_wrd =0 \n",
    "    count_comment = 0\n",
    "    wrd_list = []\n",
    "    for s in str_list:\n",
    "        count_comment+=1\n",
    "        #print(\"master str : \",s)\n",
    "        for wrd in identity_list:\n",
    "            if(wrd in s):\n",
    "                wrd_list.append(wrd)\n",
    "                count_wrd+=1\n",
    "                \n",
    "    return count_wrd,count_comment,list(set(wrd_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Analyze the words most commonly associated with each of the three types of hostile speech</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul><p><li>We call the function <strong>identityInComment</strong> by passing in the cleaned up comments that are perceived personal attacks and also the list of identity words representing targeted groups that appear in these comments\n",
    "\n",
    "We can infer from above code that some of the common words associated with each of the 3 types of hostile speech are <strong>'deaf', 'blind', 'muslim', 'gay', 'black', 'woman', 'sexuality', 'feminist','destroy', 'loser', 'kill', 'hate', 'attack'</strong></li></p>\n",
    "\n",
    "<p><li>The function <strong>kFreqWord</strong> takes in 2 arguments and provies the list of top k frequently used words in the comments.</li></p>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>The below code chunk does the following</strong>\n",
    "<ul><li>Get the comments from the dataframe where attack column is True using dataframe.query into the list 'str_list'</li>\n",
    "    <li>Define the list that contains some identity words as 'identity_list'</li>\n",
    "    <li>Define the list that contains some words pertaining to hatespeech as 'hatespeech_list'</li>\n",
    "    <li>Call the function identityInComment by passing in the arguments str_list and identity_list and get the values for count of identity words that appeared in these many number of comments and also the actual identity words</li>\n",
    "    <li>Call the function identityInComment by passing in the arguments str_list and hatespeech_list and get the values for count of hatespeech words that appeared in these many number of comments and also the actual hatespeech words</li>\n",
    "    <li>Provides the list of top 50 frequently used words from the comments</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of times identity words appeared in comments that are perceived as attacks ==> 717  times identity words in 13590  comments \n",
      "Identity words that appeared in the list:  ['African', 'Asian', 'deaf', 'blind', 'muslim', 'gay', 'black', 'woman', 'sexuality', 'feminist']\n",
      "\n",
      "Number of times hate-speech words appeared in comments that are perceived as attacks ==> 1707  times hateful words in 13590  comments \n",
      "Hate-speech words that appeared in the list:  ['destroy', 'loser', 'kill', 'terror', 'hate', 'attack']\n",
      "\n",
      "Most frequently occuring words in comments:  [('==', 3499), ('`', 1622), ('I', 408), ('You', 303), ('Fuck', 120), ('you', 114), ('YOU', 90), ('fuck', 77), ('FUCK', 74), ('This', 74), ('What', 67), (':', 67), ('Hey', 65), ('.', 65), ('i', 64), ('::', 63), (',', 63), ('Why', 62), ('Go', 60), (\"You're\", 57), ('Your', 52), ('hey', 42), ('Oh', 41), ('The', 40), (\"I'm\", 35), ('and', 35), ('How', 35), ('Please', 34), ('Are', 34), ('If', 31), ('And', 31), ('Stop', 30), ('Do', 29), ('==You', 28), ('Who', 28), (':I', 26), ('So', 25), ('your', 25), ('No', 25), (':::', 24), ('Shut', 23), ('==I', 23), ('*', 23), (\"Don't\", 23), ('go', 22), ('Get', 22), (':You', 21), ('-', 20), ('My', 20), ('::::', 19)]\n"
     ]
    }
   ],
   "source": [
    "str_list = personal_attacks_comments.query('attack')['comment']\n",
    "identity_list = ['black', 'muslim', 'feminist', 'woman', 'gay','deaf','blind','African','Asian','sexuality']\n",
    "hatespeech_list = ['kill','hate','loser','destroy','attack','terror']\n",
    "print()\n",
    "count_wrd,count_comment,lst = identityInComment(str_list,identity_list)  \n",
    "print(\"Number of times identity words appeared in comments that are perceived as attacks ==>\", count_wrd , \" times identity words in\" , count_comment, \" comments \") \n",
    "print(\"Identity words that appeared in the list: \",lst)\n",
    "print()\n",
    "count_wrd_hate,count_comment_hate,lst = identityInComment(str_list,hatespeech_list) \n",
    "print(\"Number of times hate-speech words appeared in comments that are perceived as attacks ==>\", count_wrd_hate , \" times hateful words in\" , count_comment_hate, \" comments \") \n",
    "print(\"Hate-speech words that appeared in the list: \",lst)\n",
    "print()\n",
    "topk_occur = kFreqWord(str_list,50)\n",
    "print(\"Most frequently occuring words in comments: \",topk_occur) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>The below code chunk does the following</strong>\n",
    "<ul><li>Get the comments from the dataframe where toxicity column is True using dataframe.query into the list 'str_list'</li>\n",
    "    <li>Define the list that contains some identity words as 'identity_list'</li>\n",
    "    <li>Define the list that contains some words pertaining to hatespeech as 'hatespeech_list'</li>\n",
    "    <li>Call the function identityInComment by passing in the arguments str_list and identity_list and get the values for count of that appeared in these many number of comments and also the actual identity words</li>\n",
    "    <li>Call the function identityInComment by passing in the arguments str_list and hatespeech_list and get the values for count of hatespeech words that appeared in these many number of comments and also the actual hatespeech words</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of times identity words appeared in comments that are perceived as toxic ==> 812  times identity words in 15362  comments \n",
      "Identity words that appeared in the list:  ['African', 'Asian', 'deaf', 'blind', 'muslim', 'gay', 'black', 'woman', 'sexuality', 'feminist']\n",
      "\n",
      "Number of times hate-speech words appeared in comments that are perceived as toxic ==> 1891  times hateful words in 15362  comments \n",
      "Hate-speech words that appeared in the list:  ['destroy', 'loser', 'kill', 'terror', 'hate', 'attack']\n",
      "\n",
      "Most frequently occuring words in comments:  [('==', 3888), ('`', 1861), ('I', 454), ('You', 313), ('you', 122), ('Fuck', 119), ('YOU', 101), ('This', 85), ('What', 81), ('fuck', 81), (':', 80), ('.', 76), ('FUCK', 74), ('Hey', 71), ('::', 69), (',', 67), ('i', 66), ('Why', 63), (\"You're\", 63), ('Go', 62), ('The', 51), ('Your', 50), (\"I'm\", 46), ('Oh', 44), ('If', 41), ('and', 40), ('hey', 40), ('And', 39), ('Stop', 39), (':I', 35), (':::', 33), ('How', 33), ('Are', 33), ('Please', 31), ('::I', 30), ('Who', 30), ('your', 29), ('No', 29), ('Do', 29), (\"Don't\", 29), ('*', 28), ('So', 26), ('==You', 26), (\"It's\", 26), ('It', 25), (':You', 25), ('Get', 24), ('is', 24), ('this', 23), ('==I', 23)]\n"
     ]
    }
   ],
   "source": [
    "str_list = toxicity_comments.query('toxicity')['comment']\n",
    "identity_list = ['black', 'muslim', 'feminist', 'woman', 'gay','deaf','blind','African','Asian','sexuality']\n",
    "hatespeech_list = ['kill','hate','loser','destroy','attack','terror']\n",
    "print()\n",
    "count_wrd,count_comment,lst = identityInComment(str_list,identity_list)\n",
    "print(\"Number of times identity words appeared in comments that are perceived as toxic ==>\", count_wrd , \" times identity words in\" , count_comment, \" comments \")  \n",
    "print(\"Identity words that appeared in the list: \",lst)\n",
    "print()\n",
    "count_wrd_hate,count_comment_hate,lst = identityInComment(str_list,hatespeech_list) \n",
    "print(\"Number of times hate-speech words appeared in comments that are perceived as toxic ==>\", count_wrd_hate , \" times hateful words in\" , count_comment_hate, \" comments \")\n",
    "print(\"Hate-speech words that appeared in the list: \",lst)\n",
    "print()\n",
    "topk_occur = kFreqWord(str_list,50)\n",
    "print(\"Most frequently occuring words in comments: \",topk_occur) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>The below code chunk does the following</strong>\n",
    "<ul><li>Get the comments from the dataframe where aggression column is True using dataframe.query into the list 'str_list'</li>\n",
    "    <li>Define the list that contains some identity words as 'identity_list'</li>\n",
    "    <li>Define the list that contains some words pertaining to hatespeech as 'hatespeech_list'</li>\n",
    "    <li>Call the function identityInComment by passing in the arguments str_list and identity_list and get the values for count of that appeared in these many number of comments and also the actual identity words</li>\n",
    "    <li>Call the function identityInComment by passing in the arguments str_list and hatespeech_list and get the values for count of hatespeech words that appeared in these many number of comments and also the actual hatespeech words</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of times identity words appeared in comments that are perceived as aggressive ==> 712  identity words in 14782  comments\n",
      "Identity words that appeared in the list:  ['deaf', 'blind', 'muslim', 'gay', 'black', 'woman', 'sexuality', 'feminist']\n",
      "\n",
      "Number of times hate-speech words appeared in comments that are perceived as aggressive ==> 1841  hateful words in 14782  comments\n",
      "Hate-speech words that appeared in the list:  ['destroy', 'loser', 'kill', 'hate', 'attack']\n",
      "\n",
      "Most frequently occuring words in comments:  [('==', 3705), ('`', 1889), ('I', 452), ('You', 321), ('Fuck', 120), ('you', 114), ('YOU', 91), ('This', 81), ('fuck', 77), ('::', 76), ('What', 75), ('FUCK', 74), (':', 73), (',', 71), ('.', 71), ('Why', 70), ('Hey', 67), ('i', 63), (\"You're\", 61), ('Go', 61), ('Your', 55), ('The', 46), ('hey', 42), ('Oh', 42), (\"I'm\", 41), ('Please', 40), ('Are', 37), ('And', 36), ('How', 36), ('Stop', 35), ('and', 35), ('If', 35), (':::', 32), ('Who', 30), ('*', 29), ('==You', 28), ('Do', 28), ('So', 27), ('your', 27), ('No', 27), (':I', 26), ('==I', 26), (\"Don't\", 25), (\"It's\", 24), ('Shut', 23), (':You', 23), ('is', 23), ('::::', 22), ('go', 22), ('::I', 22)]\n"
     ]
    }
   ],
   "source": [
    "str_list = aggression_comments.query('aggression')['comment']\n",
    "identity_list = ['black', 'muslim', 'feminist', 'woman', 'gay','deaf','blind','sexuality']\n",
    "hatespeech_list = ['kill','hate','loser','destroy','attack'] \n",
    "print()\n",
    "count_wrd,count_comment,lst = identityInComment(str_list,identity_list) \n",
    "print(\"Number of times identity words appeared in comments that are perceived as aggressive ==>\", count_wrd , \" identity words in\" , count_comment, \" comments\")\n",
    "print(\"Identity words that appeared in the list: \",lst)\n",
    "print()\n",
    "count_wrd_hate,count_comment_hate,lst = identityInComment(str_list,hatespeech_list) \n",
    "print(\"Number of times hate-speech words appeared in comments that are perceived as aggressive ==>\", count_wrd_hate , \" hateful words in\" , count_comment_hate, \" comments\")\n",
    "print(\"Hate-speech words that appeared in the list: \",lst)\n",
    "print()\n",
    "topk_occur = kFreqWord(str_list,50)\n",
    "print(\"Most frequently occuring words in comments: \",topk_occur) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Are certain words more likely to be associated with comments labelled as hostile speech? Are there certain words that are frequently associated with one type of hostile speech (like “personal attacks”) but not others (like “toxicity”)?</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Frequently occuring top 50 words do not contain hate speech except a couple. This implies that the occurance of hate-speech words is very less frequent as compared to non-hate speech words. But within the words flagged for hate-speech, Identity terms such as 'deaf', 'blind', 'muslim', 'gay', 'black', 'woman', 'sexuality', 'feminist' appear multiple times.</p>\n",
    "\n",
    "<p>The words <strong>'Asian', 'American'</strong> are identity terms associated with personal attacks and toxicity, but not aggression. As  <a href='https://cdt.org/wp-content/uploads/2017/12/FAT-conference-draft-2018.pdf'>article</a> points out, there is very low agreement between coders’ annotations of text as hate speech. There are very few details in the hate speech detection literature about how texts have been annotated, which makes it difficult to evaluate how error or bias may be occurring. Often, context and minor semantic differences separate hate speech from benign speech. We need clear, consistent definitions of the type of speech to be identified.Translating an abstract definition into a clearer and more concrete one can make annotation easier, but machines trained on these narrow definitions may miss some of the targeted speech, may be easier to evade, and may  disproportionately target one or more subtypes of the targeted speech</p>\n",
    "\n",
    "\n",
    "<p><li><strong>Unintended bias </strong> It can be observed that the frequently targeted groups, represented by the identity words such as “black”, “muslim”, “feminist”, “woman”, “gay” etc, are over-represented in abusive and toxic comments. This implies the training data used to train machines exhibit the same trend. When the training data used to train machine learning models contain these comments, ML models adopt the biases that exist in these underlying distributions.These identity terms of targeted groups appear far more often in abusive comments. It is much rarer for these words to appear in a positive, affirming statements.</li></p>\n",
    "\n",
    "<p><li><strong>False positives: </strong> Flagging identity terms as hate-speech results in False Positives.There is little agreement on what actually constitutes hate speech. Translating an abstract definition into a clearer and more concrete one can make annotation easier, but doing so comes with its own risks. Tools that rely on narrow definitions will miss some of the targeted speech, may be easier to evade, and may be more likely to disproportionately target one or more subtypes\n",
    "of the targeted speech. The general rule that false negatives and false positives should be balanced. However, this\n",
    "assumption ignores the particular stakes of decisions that affect a person’s human rights, liberty interests,\n",
    "or access to benefits </li></p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Are these words representative of words that you would associate with hostile speech? Do you think these frequently labelled words are a good representation of hostile speech in online discussions outside of Wikipedia? Of offline discussions? Why or why not?</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul><li>It can be observed that the frequently targeted groups, represented by the identity words such as “black”, “muslim”, “feminist”, “woman”, “gay” etc, are over-represented in abusive and toxic comments. These words are not representative of words that you would associate with hostile speech. This implies the training data used to train machines exhibit the same trend. When the training data used to train machine learning models contain these comments, ML models adopt the biases that exist in these underlying distributions.These identity terms of targeted groups appear far more often in abusive comments. It is much rarer for these words to appear in a positive, affirming statements.</li>\n",
    "\n",
    "<p><li>The frequently labelled words are definitely not a good representation of hostile speech outside Wikipedia. The raw data used for training models is very limited and is not representative of all the words that can be used to express hatefulness. White supremacists have also used innocuous terms, including the names of companies (“Google,” “Skype,” and “Yahoo”) as stand-ins for racial and ethnic slurs according to the <a href='https://cdt.org/wp-content/uploads/2017/12/FAT-conference-draft-2018.pdf'>article</a>. Users seeking to convey hateful messages could quickly adapt and begin using different novel terms and phrases. Non-English languages are underrepresented and have lower accuracy as they are not well represented on the internet, since the models have fewer examples of those languages to learn from. So, outside Wikipedia which supports very few languages,these words are not a good representation. Also, models have been trained based on wikipedia corpus which mostly supports informative topics, so outside this domain, the model may not perform well.</li></ul></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Other sources of bias</h3>\n",
    "\n",
    "<p><li><strong>Implicit or Experimenter's bias: </strong>For training classifiers, we need to create a corpus that contains a sufficient number and variety of examples of personal attacks. In order to ensure representativeness and overall prevalence of personal attack comments, comments are randomly sampled from the full corpus as well as from the blocked dataset that contains comments made by users who were blocked for violating Wikipedia’s policy on personal attacks. But this could be linked to Experimenter's bias because here the experimenter assumes that the comments from blocked dataset are indeed attacks. But thinking deeply, the comments from blocked dataset could also contain biased data. Automation tools could have scored the comments in the blocked dataset and induced some sort bias into the data. Besides this, even if the comments are attacks, they need not be personal attacks. The overall prevalence of personal attacks in the subset of corpus sampled randomly will be under-represented in the sample data. </li></p>\n",
    "\n",
    "<p><li><strong>Selection bias and false positives: </strong>This type of bias occurs when a model itself influences the generation of data that is used to train it. Blocked dataset contains comments made by users who were blocked for violating Wikipedia’s policy on personal attacks, but some of these comments could have been wrongly scored by automation tools based on Machine's learning that has induced biases and are just false positives. The below counts indicate that not all comments from the blocked dataset would necessarily be attacks. The count says 65126 comments from the blocked dataset may not be attacks at all in the first place. </li></p></ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1= personal_attacks_comments\n",
    "print(\"# records from blocked dataset considered an attack: \",len(df1[np.logical_and(df1['sample'] == 'blocked',df1['attack'] == True)]))\n",
    "print(\"# records from blocked dataset considered not an attack: \",len(df1[np.logical_and(df1['sample'] == 'blocked',df1['attack'] == False)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1= toxicity_comments\n",
    "print(\"# records from blocked dataset considered toxic: \",len(df1[np.logical_and(df1['sample'] == 'blocked',df1['toxicity'] == True)]))\n",
    "print(\"# records from blocked dataset considered not toxic: \",len(df1[np.logical_and(df1['sample'] == 'blocked',df1['toxicity'] == False)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1= aggression_comments\n",
    "print(\"# records from blocked dataset considered aggressive: \",len(df1[np.logical_and(df1['sample'] == 'blocked',df1['aggression'] == True)]))\n",
    "print(\"# records from blocked dataset considered not aggressive: \",len(df1[np.logical_and(df1['sample'] == 'blocked',df1['aggression'] == False)]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
